
Load packages.
```{r}

library(tidyverse)
library(lubridate)
library(future)
library(sjlabelled)
library(corpus)
library(REDCapR)
library(caret)
library(glmnet)
library(ROCR)
library(cowplot)

```

Settings.
```{r}

data_refresh = FALSE # Dataset is large and only needs updating sometimes. Change to TRUE to pull and process new data from RedCap

filter_to_first <- "migraine" # can set to "chronic_ha" to include other HA disorder types

headache_strings <- c(
  "headache", "migraine", "head ache", #A list of potential HA words in chief complaint
  "head pain", "\\bha\\b", "\\bh/a\\b") # Make sure to capture "ha" and "h/a" in note as well

presents_strings <- c(
  "presents(\\swith)?", "presented(\\swith)?", "presenting(\\swith)?", # A list of potential words to signify a "presenting" complaint
  "present(\\swith)?", "pw", "p/w", "here with", # Be specific to capture different verb tenses + conjugations
  "transferred", "transfers", "transfer", 
  "refers", "referred", "refer", "sent", 
  "admitted", "admits", "admit", "comes", 
  "come", "coming", "setting of", 
  "complaining", "complains", "complain")

```


Load in data dictionary to add variable labels to RedCap data
```{r}

data_dict_loc <- "raw_data/EmergencyDepartmentFormsV2_DataDictionary_2021-07-14.csv" # Location of data dictionary
data_dict <- read_csv(data_dict_loc) %>% # Read in CSV
  mutate(`Choices, Calculations, OR Slider Labels` =  map2( #If a checkbox, make sure to capture all checkbox variables
    `Choices, Calculations, OR Slider Labels`, 
    `Field Type`, ~unlist(ifelse(.y == "checkbox", str_split(.x, "(\\s+)?\\|(\\s+)?"), .x)))) %>%
  unnest(`Choices, Calculations, OR Slider Labels`) %>%
  mutate(`Choices, Calculations, OR Slider Labels` = str_trim(`Choices, Calculations, OR Slider Labels`),
         `Variable / Field Name` = ifelse(
           `Field Type` == "checkbox", glue::glue("{`Variable / Field Name`}___{gsub(',.*$', '', `Choices, Calculations, OR Slider Labels`)}"), 
           `Variable / Field Name`
           ))

```

Prep strings for regex search.
```{r}

headache_regex <- regex(
  paste0("(", headache_strings, ")", 
         collapse="|"), ignore_case = T)

presents_regex <- regex(
  paste0("(", presents_strings, ")", 
         collapse="|"), ignore_case = T)

```


Load in data. RedCAP token + URL in ignored data.
```{r}

if (data_refresh){
  
  # Get token + API needed for REDCap access
  source("raw_data/redcap_info.R") 
  
  #Get excel spreadsheet of HA diagnoses + dates given
  ha_diagnoses <- readxl::read_xlsx(path = "raw_data/ed_icd_codes.xlsx") %>%
    rename_with(tolower) %>%
    rename(mrn = pat_mrn_id) %>%
    mutate(dxdt = parse_date(dxdt, format = "%d-%b-%y")) %>%
    mutate( # Flag diagnoses that fall under chronic HA categories
      migraine = str_detect(
        icd_code, regex("G43(?!\\.[AD])|346")), 
      tth = str_detect(
        icd_code, regex("G44\\.21|G44\\.22|339\\.11|339\\.12")),
      cluster = str_detect(
        icd_code, regex("G44\\.01|G44\\.02|339.\\01|339\\.02")),
      other_ha = str_detect(
        icd_code, regex("G44\\.03|G44\\.04|G44\\.321|G44\\.51|G44\\.52|339\\.03|339\\.04|339\\.22|339\\.41|339\\.42")),
      chronic_ha = rowSums(
        across(migraine:other_ha, as.numeric)) > 0)
  
  raw2 <- redcap_read( # Read in REDCap data w/ metadata
    redcap_uri = uri,
    token =api_token,
    batch_size = 1000,
    interbatch_delay = 1,
    continue_on_error = TRUE)
  
  # Create dataframe from REDCap data. All tables are merged
  df2 <- tibble(`Variable / Field Name` = colnames(raw2$data)) %>%
    left_join( 
      select(data_dict, `Variable / Field Name`, `Field Label`),
      by = "Variable / Field Name") %>%
    mutate(`Field Label` = ifelse(
      is.na(`Field Label`), "", `Field Label`)
    ) %>%
    pull(`Field Label`) %>%
    set_label(x = raw2$data, label = .)
  
  # Create a list of dataframes for each instrument
  table_names <- paste0("data_", unique(data_dict$`Form Name`)) %>%
    set_names() %>%
    map(., \(x){ 
      temp <- df2 %>%
        select("record_id", any_of(
          data_dict %>% 
            filter(
              `Form Name` == str_remove(x, "^data_")) %>%
            pull(`Variable / Field Name`) %>% unique())) %>%
        filter(if_any(.cols = -record_id, .fns = ~ !is.na(.)))
      return(temp)
    })
  
  # Dump list of tables into global environment
  list2env(table_names, envir = .GlobalEnv)
  
  # Save dataframes to RData file
  save(
    list = c("ha_diagnoses", names(table_names)), 
    file = "raw_data/redcap_data.RData")
  
} else load("raw_data/redcap_data.RData") # Otherwise load in dataframes from RData file

```

Clean up ED admission notes. Find chief complaints.
```{r}

# Modify table of ED admission data. Find chief complaint and figure out presenting symptoms. Label if patient presents w/ headache
data_ed_admission_ha_char <-  data_ed_admission_ha_char %>%
  mutate(
    entire_note = str_replace_all( # clean up entire note for processing
      entire_note, c(
        "\\:(\\s+)?[·°º]{2,}"= "\\: ",
        "^.{0,60}(History of Present Illness\\:(\\s)+)" = "", 
        "[^[:alnum:]]+\\?" = "",
        "(?=\\([^\\)])\\?" = "",
        "(?<!\\([^\\)])elevated troponin?" = "(elevated troponin)",
        "Dr\\." = "Dr",
        "Mr\\." = "Mr",
        "Mrs\\." = "Mrs",
        "Ms\\." = "Ms",
        "\\.(?=.*is a)" = "",
        "St\\." = "St",
        "E\\.(\\s+)?coli" = "E coli")),
    entire_note_sentences = map( # split note into smaller sections based on [·°º] symbols
      entire_note, ~unlist(str_split(
        .x, regex("(?<!\\:)(\\s+)?[·°º]{2,}(\\s+)?", 
                  ignore_case = TRUE)))),
    one_liner = str_trim( # Select section with observed chief complaint based on "CC:" or "presents with" annotation present. Otherwise, select the first section w/in note
      map_chr(entire_note_sentences, 
          \(x){
            
            y = str_subset(
              str_subset(x, regex("(CC\\:)|(\\bis a\\b)|(presents)", ignore_case = T)),
              "Source", negate = TRUE)
            
            z = if (length(y) > 1) {
              if (str_detect(y[[1]], 
                             regex("(CC\\:)|(\\bis a\\b)", ignore_case = T)) &
                  str_detect(y[[2]], 
                             regex("(presents)", ignore_case = T))) {
                str_c(y[1:2], collapse = " ")
                
              } else y[[1]]
            } else if (length(y) == 1) {
              
              y[[1]]
              
            } else str_c(x[[1]], collapse = " ")
            
            return(z)})),
    presents_with = # Find the presenting complaint w/in chief complaint (need to remove children with history of headache mentioned but not the presenting complaint)
      map_chr(one_liner, 
          \(x){
            y = unlist(str_split(x, boundary("sentence")))
            z = str_trim(
              case_when(
              any(str_detect(y, presents_regex)) ~ first(na.omit(str_extract(y, regex(
                paste0("(", presents_strings, ".*$)", collapse="|"), 
                ignore_case = T)))),
              str_length(first(y)) < 25 ~ first(y),
              str_detect(first(y), regex("\\bwith\\b|\\bw\\b|\\bw\\\b")) ~ str_remove(
                first(y), regex("^.*(\\bwith\\b|\\bw\\b|\\bw\\\b)(?!.*\\b\\1\\b)"))))
            
            return(z)}),
         ha_in_oneliner = str_detect( #Flag if headache within string one liner
           presents_with, 
           regex(paste0("(", headache_strings, ")", 
                        collapse="|"), ignore_case = T)),
         ha_in_cc = str_detect( # Flag if headache was marked by complaint note (often does not line up)
           chief_comp, 
           regex(paste0("(", headache_strings, ")", 
                        collapse="|"), ignore_case = T)))

```

From list of HA-related diagnoses, label date of first diagnosis
```{r}

ha_diagnoses_first <- ha_diagnoses %>%
  filter(.data[[filter_to_first]]) %>% # Filter to first MIGRAINE diagnosis
  group_by(mrn) %>% # For each patient
  mutate(across(migraine:other_ha, ~ifelse(.x, as.character(dxdt), NA))) %>% # Find the first date of diagnosis for each HA category
  summarise(across(migraine:other_ha, ~{ymd(first(na.omit(.x)))}),
            first_dx = first(dxdt)) 

```

Merge with demographic data. Compile list of past comorbid diagnoses.
```{r}

data_demographics <- data_demographics %>% # Add Dx date info to demographics table
  left_join(ha_diagnoses_first, by = "mrn")

data_diagnosis <- data_diagnosis %>% # Prepare list of relevant medical history. Focus on diagnoses PRIOR to ED visit
  mutate(past_cond = as.numeric(
    rowSums(across(starts_with("past"), 
                   ~replace_na(.x, 0))) > 0))

```


Select first ED visit w/ CC of headache or migraine
```{r}

# Symptoms may appear across multiple columns. 
# Label as 1 if flagged in ANY of the listed columns.
# Label as NA if all columns marked NA.
# Label as 0 otherwise
rowsum_columns <- \(x){
  if (all(is.na(c_across(all_of(x))))){
    y = NA_real_
  } else {
    y = as.numeric(sum(c_across(all_of(x)), na.rm = TRUE) > 0)
  }
  return(y)
}


data_ed_first_visits <- data_ed_admission_ha_char %>%
  filter(ha_in_oneliner) %>% # Select HA related visits
  filter(between(age, 3, 17)) %>% # Restrict to 3-17yos
  filter(contact_date < as.Date("2020-03-01")) %>% # Restrict to visit before March 2020 (in case of pandemic interference)
  group_by(record_id) %>%
  filter(row_number() == 1) %>% ungroup() %>% # Find first visit
  left_join( # Add in demographic data
    data_demographics %>% 
      select(record_id, first_dx, sex, dob, race, ethnicity), 
    by = "record_id") %>%
  mutate(dx_before = case_when( #Find cases with Dx prior to first ED visit
    contact_date >= first_dx ~ 1,
    contact_date <= first_dx ~ 0,
    is.na(first_dx) ~ 0
  )) %>%
  filter(dx_before == 0) %>% # Remove those cases
  select(-dx_before) %>%
  left_join( # Merge in data on past medical history
    data_diagnosis %>% 
      select(record_id, csn_id_adm = csn_dx, past_cond),
    by = c("record_id", "csn_id_adm")) %>%
  mutate(age = as.numeric(as.duration( # Calculate age & clean up factors
    interval(dob, contact_date)), "years"),
    sex = factor(sex, levels = 1:2, labels = c("Female", "Male")),
    race = factor(race, levels = c(1:8,99), labels = c(
      "American Indian or Alaska Native", "Asian", "Black",
      "Native Hawaiian or Other Pacific Islander", "White", 
      "Multiracial", "Other", "Other", "Other")),
    ethnicity = case_when(
      ethnicity == 1 ~ 1,
      ethnicity == 2 ~ 0,
      TRUE ~ NA_real_),
    dx_within_twelve = case_when( # Label if migraine Dx w/in 12 mos of visit
      first_dx == contact_date ~ 1, 
        first_dx %within% interval(
          contact_date, contact_date+years(1)) ~ 1,
      TRUE ~ 0),
    woke_from = map_dbl(entire_note_sentences, \(x){ #Test: Find mentions of HA waking from sleep. Not included in final model due to high missingness
      
      y =  str_subset(
        unlist(str_split(x, boundary("sentence"))),
        regex("((\\bwake)|(\\bwaking)|(\\bwoke)|(\\bawake)|(\\bawoke)).{0,40}((from sleep)|((complain|(due to)|from).{0,10}(head|ha\\b|h/a\\b|migraine|pain)))", 
              ignore_case = TRUE))
      
      z = case_when(
        any(str_detect(y, regex("((denie)|(deny)|(not)|(didnt)|(didn\\'t)).{0,20}((\\bwake)|(\\bwaking)|(\\bwoke)|(\\bawake)|(\\bawoke)).{0,40}((from sleep)|((complain|(due to)|from).{0,10}(head|ha\\b|h/a\\b|migraine|pain)))",
                                ignore_case = TRUE))) ~ 0,
        any(str_detect(y, regex("((\\bwake)|(\\bwaking)|(\\bwoke)|(\\bawake)|(\\bawoke)).{0,40}((from sleep)|((complain|(due to)|from).{0,10}(head|ha\\b|h/a\\b|migraine|pain)))",
                                ignore_case = TRUE))) ~ 1,
        TRUE ~ NA_real_
      )
      
      return(z)
    })) %>%
  rowwise() %>% #Split data for rowwise calculations
  mutate( # Find symptoms across redundant columns
    nausea_vomit = rowsum_columns(
      c("assoc_sx___nausea", "assoc_sx___vomit", 
        "gi_prob___vomit")),
    photo_phono = rowsum_columns(
      c("assoc_sx___photo", "assoc_sx___noise")),
    fever_total = case_when(
      rowsum_columns(
        c("fever", "overall_prob___fever")) == 1 ~ 1,
      str_detect(fever_oth, "yes|chill") ~ 1,
      is.na(fever_oth) & is.na(fever) & is.na(overall_prob___fever) ~ NA_real_,
      TRUE ~ 0),
    numb_sensory = rowsum_columns(
      c("assoc_sx___numb", "assoc_sx___sensory",
        "neuro_prob___numb")),
    dizzy = case_when( #Find mentions of dizziness
      heart_prob___dizzy == 1 ~ 1, 
        str_detect(assoc_sx_oth, 
                   regex("(dizzy)|(dizziness)")) ~ 1,
      is.na(heart_prob___dizzy) & is.na(assoc_sx_oth) ~ NA_real_,
      TRUE ~ 0
        ),
    awaken = case_when( # Test: Find if woken from sleep by HA. Not included in final model due to high missingness
      awaken == 1 ~ 1,
      awaken == 0 ~ 0,
      str_detect(awaken_oth, 
                 regex("(yes)|(\\by\\b)", 
                       ignore_case = T)) ~ 1,
      str_detect(awaken_oth, 
                 "but today HA") ~ 1,
      str_detect(awaken_oth, 
                 regex("(\\bno\\b)|(never)|(\\bn\\b)", 
                       ignore_case = T)) ~ 0,
      woke_from == 1 ~ 1,
      woke_from == 0 ~ 0,
      TRUE ~ NA_real_
    ),
    past_cond = ifelse(is.na(past_cond), # Flag if PMH included conditions relevant to secondary headache
                       0, past_cond),
    off_hours = as.numeric( # Label if visit occurred in off-hours (from 7PM - 7AM)
      !between(contact_time, 
               hm("07:00"), hm("19:00"))),
    severity_oth = ifelse( # Find mentions of pain severity within note if pain rating is unclear
      severity %in% c(999, 9999) & 
        severity_oth == 'Pain severity: "',
      map_chr(entire_note_sentences, ~str_c(
        str_subset(.x, regex("pain severity", ignore_case = T)),
        collapse = "; ")),
      severity_oth),
    side = relevel(fct_collapse( # Collapse categories for side. Unilateral at baseline
      side, 
      `bilateral` = c("bi"),
      `unilateral` = c("right", "left", "uni_l_r"),
      `other` = c("oth")), ref = "unilateral"),
    severity_new = case_when( # Mark if HA rated 7+ out of 10 or described as "severe" or "excruciating" or "very bad"
      severity %in% 7:10 ~ 1,
           severity %in% 0:6 ~ 0,
           severity %in% c(999, 9999) & str_detect(entire_note, regex("(7|8|9|(10))(\\s+)?(\\/|(out)? of)(\\s+)?10", ignore_case = T)) ~ 1,
           severity %in% c(999, 9999) & str_detect(severity_oth, regex("((?<!(most|more).{0,10})severe)|devere|excruciating|\\b(7|8|9|(?<![0-9/].{0,3})10)\\b(?!.{0,10}(hour|\\bmins|minute|day))|(very bad)", ignore_case = T)) ~ 1,
           severity %in% c(999, 9999) & str_detect(severity_oth, regex("mild|moderate", ignore_case = T)) ~ 0,
           severity %in% c(999, 9999) & str_detect(entire_note, regex("([0-6](\\s+)?(\\/|(out)? of)(\\s+)?10)|(\\b[0-6]\\b(?!.{0,10}(hour|\\bmins|minute|day)))", ignore_case = T)) ~ 0
           )) %>%
  ungroup()


```

Remove extraneous variables. Select complete-case data. 
```{r}

data_ed_first_visits_complete <- data_ed_first_visits %>%
  mutate(train = as.numeric(contact_date < as.Date("2019-01-01")), #Mark training data as occurring before 01/01/2019
         age = scale(age))  %>% # Scale and center age
  select( # Select predictors of interest + record_ID
    record_id, dx_within_twelve, train, 
    contact_date, age, sex, past_cond,
    occipital = location___occ, 
    fever_total, nausea_vomit, 
    photophobia = assoc_sx___photo, phonophobia = assoc_sx___noise,
    vision_changes = assoc_sx___vision, dizzy,
    worsen_activity = assoc_sx___active,
    altered_mental = neuro_prob___alt_mental,
    side, severity_new) %>%
  filter(complete.cases(.)) # Restrict to complete cases
  

```


Count of first ED visits by year. Marking training vs. testing data by fill color.
```{r}

data_ed_first_visits_complete %>%
  mutate(year = year(contact_date)) %>%
ggplot(data = ., aes(year, fill = factor(train))) +
  geom_bar(stat = "count") +
  labs(x = "Year", y = "Count") +
  ggthemes::scale_fill_ptol() +
  ggthemes::theme_tufte(
    base_size = 20, base_family = "sans") +
  theme(legend.position = "none")

```
 
Separate training + test data. One-hot encode data.
```{r}

# Find training data. Resampling here only because I plan on using this data in the future and didn't want to know too much :)
data_ed_first_visits_train <- data_ed_first_visits_complete %>%
  filter(train == 1) %>%
  select(-record_id, -train, -contact_date) %>%
  slice_sample(n = nrow(.), replace = TRUE)

#Find testing data
data_ed_first_visits_test <- data_ed_first_visits_complete %>%
  filter(train == 0) %>%
  select(-record_id, -train, -contact_date)

# One-hot encode both datasets
encoder <- onehot::onehot(data_ed_first_visits_train)
data_ed_first_visits_train_encode <- predict(encoder, data_ed_first_visits_train)
data_ed_first_visits_test_encode <- predict(encoder, data_ed_first_visits_test)

```


Train elastic net model. Predict for test + training data
```{r}

set.seed(42) # Set seed for reproducibility

# Train elastic net model 
ed_elnet2 <- cv.glmnet(
  x = data_ed_first_visits_train_encode[,-1],
          y = data_ed_first_visits_train_encode[,1],
          family = "binomial", # Logistic regression
          nfolds = 10, # 10-fold cross-validation
          relax = TRUE, # Allows for L2 penalty for collinearity (medical symptoms often run together like photophobia + phonophobia)
          gamma = seq(0,1,0.1)) # Allow for wide range of gamma values (mixing of L1 and L2 penalties)

elnet_train_preds <- as.vector( # Predict probabilities for training data
  predict(
    ed_elnet2, type = "response", 
    s = "lambda.1se", gamma = "gamma.1se", # Select simplest model w/in 1SE of best performing model
    as.matrix(data_ed_first_visits_train_encode[,-1])
  ))

# Repeat for testing data
elnet_test_preds <- as.vector(
  predict(
    ed_elnet2, type = "response", 
    s = "lambda.1se",  gamma = "gamma.1se",
    as.matrix(data_ed_first_visits_test_encode[,-1])
  ))

```

Find coefficients for best performing model. Plot binomial deviance measures across models.
```{r}

plot(ed_elnet2, label = T, xvar = 'lambda') # Plot performance across tuning models

coef(ed_elnet2, s = "lambda.1se", gamma = "gamma.1se") # Print coefficients for chosen model

```

Plot prediction performance for test data.
```{r}

elnet_prediction <- prediction( # Create prediction object for test data
  elnet_test_preds,
  data_ed_first_visits_test_encode[,1])

# Plot AUC curve
plot(performance(elnet_prediction, 'tpr', 'fpr'), col = 'green')
lines(c(0,1),c(0,1),col = "gray", lty = 4 ) # Add diag line for comparison


```

Create calibration plot
```{r}

tibble(y =  factor(data_ed_first_visits_test_encode[,1]),
         mod = elnet_test_preds) %>%
  calibration(y ~ mod, data = ., cuts = 10) %>%
  ggplot(.) + 
  ggthemes::theme_tufte(base_size = 20, base_family = "sans")

```

Calculate AUC with 95% CI
```{r}

pROC::auc(factor(data_ed_first_visits_test_encode[,1]), 
          elnet_test_preds) # Calculate AUC

pROC::ci.auc(factor(data_ed_first_visits_test_encode[,1]), 
             elnet_test_preds, conf.level = 0.95,
             boot.stratified = T,
             method = "bootstrap") #Calculate AUC CI via bootstrap model

```

Find PPV/NPV at different thresholds. Find Kappa at threshold >= 0.2
```{r}

threshold_performance <- seq(0.05,0.95, 0.05) %>%
  map_df(., \(x){
    threshold = x
    
    y = tibble(threshold = threshold,
               obs =  data_ed_first_visits_test_encode[,1],
           pred_prob = elnet_test_preds,
           pred_resp = as.numeric(pred_prob >= threshold),
           correct = as.numeric(obs == pred_resp))
    
    ppv = y %>%
      group_by(threshold, pred_resp) %>%
      summarise(prop_correct = mean(correct)) %>%
      mutate(pred_resp = factor(pred_resp, 
                                levels = c(0,1),
                                labels = c("NPV", "PPV"))) %>%
      pivot_wider(names_from = pred_resp, values_from = prop_correct) 

    
    return(ppv)
  })

# Compare performance between testing + training data. Slight overfit.
confusionMatrix(
  data = as.factor(elnet_test_preds >= 0.2), 
  reference = factor(data_ed_first_visits_test_encode[,1] == 1),
  positive = "TRUE"
  )

confusionMatrix(
  data = as.factor(elnet_train_preds >= 0.2), 
  reference = factor(data_ed_first_visits_train_encode[,1] == 1),
  positive = "TRUE"
  )

```


Compare model performance across racial groups.
Note: Model was NOT trained on race!
```{r}

# Create dataset for testing data adding back in race + ethnicity data
test_demographics <- data_ed_first_visits_complete %>%
  filter(train == 0) %>%
  left_join(data_ed_first_visits %>% 
              select(record_id, race, ethnicity),
            by = "record_id") %>%
  mutate(
    pred_probs = elnet_test_preds,
    ethnicity = factor(
      ethnicity, levels = c(1,0), 
      labels = c("Hispanic", "Non-Hispanic")),
    race = fct_lump_n(race, n = 3)) %>%
  select(record_id, dx_within_twelve, sex, race, 
         ethnicity, pred_probs) 

# Create function to create plots comparing performance across demographic subgroups
plot_demographic <- function(parameter, parameter_name = parameter, font_size = 12) {
  
  test_demographics %>%
    pivot_longer(cols = c(dx_within_twelve, pred_probs)) %>%
    mutate(name = case_when(
      name == "dx_within_twelve" ~ "Observed",
      name == "pred_probs" ~ "Predicted"
    )) %>%
    filter(across(parameter, ~!is.na(.x))) %>%
    group_by(across(c(parameter, "name"))) %>%
    summarise(mean_se(value, mult = 1.96),
              .groups = "drop") %>%
    ggplot(., aes_string(
      x = parameter, y = "y", 
                  ymin = "ymin", ymax = "ymax",
                  fill = "name", group = "name")) +
    geom_col(width = 0.5, position = "dodge") +
    geom_errorbar(width = 0.2, position = position_dodge(0.5)) +
    scale_y_continuous(limits = c(0,0.35), breaks = seq(0,0.35,0.05)) +
    labs(x = parameter_name, 
         y = "Proportion with\nMigraine Dx",
         fill = "") +
    ggthemes::scale_fill_ptol(guide = guide_legend(nrow = 1)) +
    ggthemes::theme_tufte(base_size = font_size, 
                          base_family = "sans") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "bottom")
  
}

# Create plots comparing performance across race, ethnicity, and gender (gender was included in original model) 
race_plot <- plot_demographic("race", "Race")
eth_plot <- plot_demographic("ethnicity", "Ethnicity")
gender_plot <- plot_demographic("sex", "Gender")

# Create cowplot lining up the 3 plots
plot_grid(
  race_plot + theme(legend.position = "none"), 
  eth_plot + theme(legend.position = "none"), 
  gender_plot + theme(legend.position = "none"),
  nrow = 1, align = "hv") %>%
plot_grid(
  ., get_legend(race_plot),
  nrow = 2, rel_heights = c(1, 0.1))


```


 









